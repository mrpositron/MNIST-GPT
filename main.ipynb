{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8018218a30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import get_data\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "# seed everything for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "openai_api_key = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "client = OpenAI(api_key = openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_ds = datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "test_ds = datasets.MNIST('../data', train=False,\n",
    "                    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = [t for t in range(len(train_ds))]\n",
    "random.shuffle(indices)\n",
    "\n",
    "x = []\n",
    "for i in range(10):\n",
    "    for j in indices:\n",
    "        val = train_ds[j][1]\n",
    "        if val == i:\n",
    "            img, _, coords, coords_str = get_data(train_ds[j])\n",
    "            x.append((img, coords, val, coords_str))\n",
    "            break\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    img = np.zeros((28, 28))\n",
    "    coords = x[i][1]\n",
    "    for coord in coords:\n",
    "        img[coord[0], coord[1]] = 1\n",
    "\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    # plt.imshow(x[i][0].reshape(28, 28), cmap='gray')\n",
    "    # plt.title(x[i][2])\n",
    "    plt.axis('off')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 784 into shape (14,14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     img[coord[\u001b[38;5;241m0\u001b[39m], coord[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# plt.imshow(img, cmap='gray')\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# plt.title(x[i][2])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (14,14)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    img = np.zeros((28, 28))\n",
    "    coords = x[i][1]\n",
    "    for coord in coords:\n",
    "        img[coord[0], coord[1]] = 1\n",
    "\n",
    "    # plt.imshow(img, cmap='gray')\n",
    "    plt.imshow(x[i][0].reshape(28, 28), cmap='gray')\n",
    "    # plt.title(x[i][2])\n",
    "    plt.axis('off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_message(value: str):\n",
    "    import re\n",
    "    instruction = \"\"\"\n",
    "Given (x, y) coordinates of non-zero pixels in a 28x28 grayscale image representing a digit, classify the digit between 0 and 9. \n",
    "Input format: \"(x0,y0);(x1,y1);(x2,y2);...\" with coordinates sorted first in the x-axis and then in the y-axis. \n",
    "PLEASE RETURN ONLY the digit number in brackets, e.g., if the digit is 3, return \"(3)\".\n",
    "\"\"\"\n",
    "\n",
    "    examples = \"\"\"\n",
    "Examples:\n",
    "(0): (4,18);(22,7);(17,20);(11,9);(21,14);(10,21);(7,13);(16,7);(8,17);(14,22);(19,17);(23,11);(7,20);(10,12);(19,8);(5,15);(14,9);(8,11);(9,14);(12,20);(21,9);\n",
    "(1): (3,14);(22,11);(17,20);(12,13);(7,10);(17,14);(21,17);(8,15);(20,14);(5,12);(5,15);(7,13);(9,9);(10,14);(14,14);(18,12);(18,18);(19,16);(22,15);(9,11);(19,20);\n",
    "(2): (8,4);(19,23);(24,10);(7,17);(17,15);(13,20);(6,10);(22,16);(19,11);(9,13);(18,19);(9,8);(11,17);(6,14);(16,22);(23,13);(6,7);(9,19);(15,18);(20,14);(5,12);\n",
    "(3): (4,15);(23,10);(15,19);(12,11);(6,8);(21,16);(9,16);(19,8);(19,19);(5,11);(12,15);(22,13);(12,18);(6,17);(10,14);(5,13);(12,13);(17,19);(19,17);(21,8);(21,10);\n",
    "(4): (7,21);(16,4);(21,20);(6,9);(15,13);(14,23);(11,6);(16,18);(18,9);(11,19);(15,7);(17,21);(9,9);(11,22);(13,4);(14,20);(17,15);(6,19);(8,7);(9,20);(15,16);\n",
    "(5): (5,22);(24,4);(19,18);(8,8);(21,11);(13,14);(6,15);(9,12);(15,18);(24,8);(9,17);(19,14);(5,18);(6,11);(6,20);(7,13);(11,11);(14,16);(17,17);(20,16);(22,7);\n",
    "(6): (2,19);(21,12);(9,10);(14,21);(15,7);(15,14);(5,14);(19,18);(13,10);(17,10);(8,13);(13,18);(20,15);(5,17);(17,21);(3,16);(11,9);(12,20);(14,16);(15,19);(17,13);\n",
    "(7): (5,13);(24,8);(16,16);(10,17);(21,13);(6,9);(13,16);(7,15);(18,14);(22,10);(12,18);(5,11);(7,13);(9,15);(24,10);(6,12);(6,14);(8,16);(11,16);(14,17);(20,12);\n",
    "(8): (4,14);(23,13);(14,17);(11,8);(7,20);(19,18);(11,13);(17,13);(10,17);(7,12);(20,12);(22,16);(14,14);(9,10);(8,18);(12,10);(12,15);(16,18);(6,14);(12,17);(20,16);\n",
    "(9): (6,13);(25,20);(17,9);(14,18);(8,19);(11,8);(20,17);(14,13);(8,10);(10,16);(14,7);(7,16);(17,17);(22,19);(9,12);(11,18);(12,15);(13,9);(15,10);(16,12);(10,10);\n",
    "\"\"\"    \n",
    "    # remove newlines and extra spaces\n",
    "    instruction = \"\".join(instruction.strip().split(\"\\n\"))\n",
    "    examples = \"\".join(examples.strip())\n",
    "\n",
    "    instruction += \"\\n\\n\" + examples\n",
    "\n",
    "    instruction += \"\\n\\nInput:\\n\"\n",
    "\n",
    "    instruction += value\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruction\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is 7\n",
      "The coordinates are: \n",
      "(8,21);(26,10);(7,6);(18,17);(10,13);(13,19);(20,12);(24,14);(9,17);(7,10);(14,16);(21,15);(23,11);(9,8);(11,21);(18,14);(8,12);(8,15);(10,19);(12,17);(15,18);\n"
     ]
    }
   ],
   "source": [
    "img, val, coords, coords_str = get_data(test_ds[0])\n",
    "# plt.imshow(img, cmap='gray')\n",
    "print(f\"The number is {val}\")\n",
    "print(f\"The coordinates are: \\n{coords_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((28, 28))\n",
    "for i in range(len(coords)):\n",
    "    img[coords[i][0], coords[i][1]] = 1\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_message = generate_message(coords_str)\n",
    "print(temp_message[0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=temp_message,\n",
    "    temperature=1.0,\n",
    ")\n",
    "response = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = len(test_ds)\n",
    "sample_size = 100\n",
    "\n",
    "sample_indices = np.random.choice(total_length, sample_size, replace=False)\n",
    "\n",
    "inputs = []\n",
    "for idx in tqdm(sample_indices):\n",
    "    img, val, coords, coords_str = get_data(test_ds[idx])\n",
    "    inputs.append((val, coords_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inputs))\n",
    "# save the inputs as .npy file\n",
    "np.save(\"inputs.npy\", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = len(predictions)\n",
    "for val, coords_str in tqdm(inputs[i:]):\n",
    "    temp_message = generate_message(coords_str)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=temp_message,\n",
    "        temperature=1.0,\n",
    "    )\n",
    "    response = response.choices[0].message.content\n",
    "    predictions.append(response)\n",
    "\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions as .npy file\n",
    "predictions_int = [int(x[1:-1]) for x in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt = [x[0] for x in inputs]\n",
    "y_pred = predictions_int[:]\n",
    "\n",
    "print(y_gt[:10], y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {np.mean(np.array(y_gt) == np.array(y_pred))}\")\n",
    "\n",
    "# make a confusion matrix\n",
    "confusion_matrix = np.zeros((10, 10))\n",
    "for gt, pred in zip(y_gt, y_pred):\n",
    "    confusion_matrix[gt, pred] += 1\n",
    "\n",
    "confusion_matrix = confusion_matrix / np.sum(confusion_matrix, axis=1)\n",
    "# color the confusion matrix\n",
    "# plot with values\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(confusion_matrix, cmap='viridis')\n",
    "for (i, j), val in np.ndenumerate(confusion_matrix):\n",
    "    ax.text(j, i, f\"{int(100 * val)}\", ha='center', va='center', color='white')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, val, coords, coords_str = get_data(test_ds[sample_indices[120]])\n",
    "\n",
    "print(f\"The number is {val}\")\n",
    "img = np.zeros((28, 28))\n",
    "for i in range(len(coords)):\n",
    "    img[coords[i][0], coords[i][1]] = 1\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
